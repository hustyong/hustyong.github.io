[{"content":"1.场景 最近在写redis 集群的控制面，有一个功能是删除集群中的某个redis 实例，需要在60秒内向整个集群的其他redis 实例发生forget命令，命令官方描述如下：\nCLUSTER FORGET node-id\nwhat the command really does is:\nThe specified node gets removed from the nodes table. The node ID of the removed node gets added to the ban-list, for 1 minute. The node will skip all the node IDs listed in the ban-list when processing gossip sections received in heartbeat packets from other nodes. This way we have a 60 second window to inform all the nodes in the cluster that we want to remove a node.\n2.实现思路 第一版实现：\n针对集群的每个实例，开一个goroutine去调用forget命令 goroutine调用forget命令有error时，保存在chan error中 等待所有goroutine 处理完毕返回，判断chan error变量是否为空， 空:forget成果，非空：forget失败 伪代码如下： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 var wg sync.WaitGroup errCh := make(chan error, len(clusterNodes)) //遍历所有redis 节点 for node:= range clusterNodes { wg.Add(1) go func(node *redis.ClusterNode) { defer func() { wg.Done() }() err:=forgetCmd(ctx) if err!= nil { errCh \u0026lt;- err } } } wg.Wait() select { case err := \u0026lt;-errCh: if err!= nil { forgetFail } defalut: } forgetSuccess 上述思路使用 goroutine 并发调用redis 集群每个实例forget掉 要下线实例，在正常的场景下60秒可以处理完。\n假如由于机器负载等原因导致有一个goroutine 60秒后才被执行并且redis正确回复，我们仍认为操作成功(但是已经违反了redis 60秒内调用所有节点的约束)。虽然这种场景一般不会出现，能不能在程序实现上保证60秒后超时失败，答案是肯定的，这就是我们接下来要介绍的context\n3. context 使用与实现原理 3.1 用途 首先看下context包的官方注释：\n1 2 3 // Package context defines the Context type, which carries deadlines, // cancellation signals,and other request-scoped values across API boundaries // and between processes. 概括来说，Context作用是：在协程之间传递值(可以理解为上下文)、同步取消操作信号。\n3.2 使用 举个例子：假如用户打开开关，我们需要向3个地址 发送-接收 报文，关闭时停止收发包。 实现思路是：开3个goroutine分别处理，当用户关闭时停止3个goroutine，此时可以用到CancelCtx，实现如下\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 for{ 读取用户输入代表开始 cancelctx, cancelfun := WithCancel(context.Background()) doNetwork := func(ctx context.Context, adrr string) { conn,err := Connect(adrr) done: = ctx.Done() for { // 阻塞直到发送出去 conn.Write(报文) // 阻塞直到发送出去 conn.Read(报文) select { case \u0026lt;-done: return; defalut: } } } doNetwork(cancelctx,addr1) doNetwork(cancelctx,addr2) doNetwork(cancelctx,addr3) 再次读到用户输入代表结束 //done就被close, 三个协程走到return语句结束 cancelfun(error(\u0026#34;user stop\u0026#34;)) } 3.3 实现 Context接口定义如下：\n1 2 3 4 5 6 7 8 // Context\u0026#39;s methods may be called // by multiple goroutines simultaneously. type Context interface { Deadline() (deadline time.Time, ok bool) Done() \u0026lt;-chan struct{} Err() error Value(key any) any } Deadline() :用户返回Context deadline取消的时间(到deadline时会关闭Done方法返回的chan以通知其他goroutine)，假如不支持定时取消(定时Context)ok返回false\nDone() :用于返回 接收 取消信号chan 的方法，假如Context是不可取消的实现即返回nil\nErr() :返回取消的原因(超时或者用户取消)\nValue(), 返回上下文中key对应的value(其他协程设置的value)\n3.3.1 context.WithCancel-可发送取消信号的上下文 WithCancel产生侧Context 的核心实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 // A cancelCtx can be canceled. // When canceled, it also cancels any children // that implement canceler. type cancelCtx struct { Context // protects following fields mu sync.Mutex // of chan struct{}, created lazily // closed by first cancel call done atomic.Value // set to nil by the first cancel call children map[canceler]struct{} // set to non-nil by the first cancel call err error } func WithCancel(parent Context) (ctx Context, cancel CancelFunc) { if parent == nil { panic(\u0026#34;cannot create context from nil parent\u0026#34;) } c := newCancelCtx(parent) // 注册到parent 的 children数据中 propagateCancel(parent, \u0026amp;c) return \u0026amp;c, func() { c.cancel(true, Canceled) } } // newCancelCtx returns an initialized cancelCtx. func newCancelCtx(parent Context) cancelCtx { return cancelCtx{Context: parent} } // cancel closes c.done, cancels each of c\u0026#39;s children, and, if // removeFromParent is true, removes c from its parent\u0026#39;s children. func (c *cancelCtx) cancel(removeFromParent bool, err error) { if err == nil { panic(\u0026#34;context: internal error: missing cancel error\u0026#34;) } c.mu.Lock() if c.err != nil { c.mu.Unlock() return // already canceled } c.err = err d, _ := c.done.Load().(chan struct{}) if d == nil { // 赋值一个关闭的chan,优化的部分 c.done.Store(closedchan) } else { close(d) //关闭 chan } // 遍历子节点，取消子上下文(通过close chan) for child := range c.children { // NOTE: acquiring the child\u0026#39;s lock while holding parent\u0026#39;s lock. child.cancel(false, err) } c.children = nil c.mu.Unlock() // 将自己从父节点的children中摘除 // 自己已经取消,父上下文取消时不用再管它 if removeFromParent { removeChild(c.Context, c) } } func (c *cancelCtx) Done() \u0026lt;-chan struct{} { d := c.done.Load() if d != nil { return d.(chan struct{}) } c.mu.Lock() defer c.mu.Unlock() d = c.done.Load() if d == nil { d = make(chan struct{}) c.done.Store(d) } return d.(chan struct{}) } func (c *cancelCtx) Err() error { c.mu.Lock() err := c.err c.mu.Unlock() return err } WithCancel(): 产生一个cancelCtx对象并且将cancelCtx注册到parent中(与parent是用树数据结构组织)，并且产生一个CancelFun(调用cancel方法并且并且error为Canceled\ncancle(): 关闭Done对应的chan通知所有关注它的goroutine已经取消; 取消所有子context(调用他们的cancel方法); 将自己从父context的 children中摘除(父上下文取消时不用再次取消此上下文)\n在3.2节的例子中，当用户调用cancelfun 会close Done返回的chan 并且保存 error, 此时select done就会收到信号并且返回，结束goroutine\n3.3.2 context.WithDeadline-Deadline发送取消信号的上下文 WithDeadline产生侧Context 的核心实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 // A timerCtx carries a timer and a deadline. // It embeds a cancelCtx to implement Done and Err. // It implements cancel by stopping its timer then // delegating to cancelCtx.cancel. type timerCtx struct { cancelCtx timer *time.Timer // Under cancelCtx.mu. deadline time.Time } func WithDeadline(parent Context, d time.Time) (Context, CancelFunc) { if parent == nil { panic(\u0026#34;cannot create context from nil parent\u0026#34;) } if cur, ok := parent.Deadline(); ok \u0026amp;\u0026amp; cur.Before(d) { // The current deadline is already sooner than the new one. return WithCancel(parent) } c := \u0026amp;timerCtx{ cancelCtx: newCancelCtx(parent), deadline: d, } propagateCancel(parent, c) //启动一个定时器 dur := time.Until(d) if dur \u0026lt;= 0 { c.cancel(true, DeadlineExceeded) // deadline has already passed return c, func() { c.cancel(false, Canceled) } } c.mu.Lock() defer c.mu.Unlock() if c.err == nil { c.timer = time.AfterFunc(dur, func() { c.cancel(true, DeadlineExceeded) }) } return c, func() { c.cancel(true, Canceled) } } func (c *timerCtx) Deadline() (deadline time.Time, ok bool) { return c.deadline, true } func (c *timerCtx) String() string { return contextName(c.cancelCtx.Context) + \u0026#34;.WithDeadline(\u0026#34; + c.deadline.String() + \u0026#34; [\u0026#34; + time.Until(c.deadline).String() + \u0026#34;])\u0026#34; } func (c *timerCtx) cancel(removeFromParent bool, err error) { c.cancelCtx.cancel(false, err) //调用cancelCtx.cancel() if removeFromParent { // Remove this timerCtx from its parent cancelCtx\u0026#39;s children. removeChild(c.cancelCtx.Context, c) } c.mu.Lock() if c.timer != nil { c.timer.Stop() //停止定时器 c.timer = nil } c.mu.Unlock() } WithDeadline(): 产生一个cancelCtx对象并且将cancelCtx注册到parent中(与parent是用树数据结构组织)，并且产生一个CancelFun(调用cancel方法并且error为Canceled，并且还产生一个定时器，Deadline时调用cancel方法并且error为 DeadlineExceeded\ncancle(): 调用cancelCtx.cancel()关闭Done对应的chan通知所有关注它的goroutine已经取消\u0026amp;取消所有子context(调用他们的cancel方法); 将自己从父context的 children中摘除,并且停止定时器\n** context.WithTimeout实际上还是context.WithDeadline，只是设置的Deadline为time.Now().Add(timeout**\n1 2 3 func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) { return WithDeadline(parent, time.Now().Add(timeout)) } 4.使用context优化实现 通过第3节可以知道，context.WithTimeout产生的Context可以在timeout时产生取消信号， 而go-redis访问redis服务器时会关注Context的取消信号，因此我们以产生一个60秒超时的Context,控制goroutine中的forget操作在60秒后直接返回error。 实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 var wg sync.WaitGroup errCh := make(chan error, len(clusterNodes)) timeOutCtx, cancel := context.WithTimeout(ctx, time.Second*60) // 遍历所有redis 节点 for node:= range clusterNodes { wg.Add(1) go func(node *redis.ClusterNode) { defer func() { wg.Done() }() err:=forgetCmd(timeOutCtx) if err!= nil { errCh \u0026lt;- err // 有一个redis实例执行错误,forget失败 // 其他goroutine也都可以直接结束了 cancel() } }() if timeOutCtx.Err() != nil { break } } wg.Wait() // 可重入，此次有可能是正常结束 // 定时器可能还没有释放，需要调用cancel() cancel() select { case err := \u0026lt;-errCh: if err!= nil { forgetFail } defalut: } forgetSuccess 5. 使用chan 控制goroutine 第4节的实现，我们实现了：\n60秒后立刻取消未完成的goroutine 出现error主动结束正在进行的goroutine并且不再创建新goroutine 但是仍然存在一个问题，就是redis集群很大的时候(1000个实例)，假如我们可能同时操作n个大集群，每个集群m个节点，那么可能产生的goroutine数量为： n=100, m=10, n * m * 1000= 100w个goroutine，直接会把内存撑爆，因此需要控制goroutine数。 针对goroutine问题，我们可以使用chan来控制数量，实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 // chan 控制goroutine数 batchCh := make(chan struct{}, batchForgetSize) var wg sync.WaitGroup errCh := make(chan error, len(clusterNodes)) timeOutCtx, cancel := context.WithTimeout(ctx, time.Second*60) // 遍历所有redis 节点 for node:= range clusterNodes { // goroutine num control batchCh \u0026lt;- struct{}{} wg.Add(1) go func(node *redis.ClusterNode) { defer func() { \u0026lt;-batchCh wg.Done() }() err:=forgetCmd(timeOutCtx) if err!= nil { errCh \u0026lt;- err // 有一个redis实例执行错误,forget失败 // 其他goroutine也都可以直接结束了 cancel() } }() if timeOutCtx.Err() != nil { // 存在错误(forget收到报错人为取消\u0026amp;超时取消) // forget失败，不用创建其他goroutine处理了 break } } wg.Wait() // 可重入，此次有可能是正常结束 // 定时器可能还没有释放，需要调用cancel() cancel() select { case err := \u0026lt;-errCh: if err!= nil { forgetFail } defalut: } forgetSuccess ","permalink":"https://www.aiforagc.com/posts/go_context/","summary":"1.场景 最近在写redis 集群的控制面，有一个功能是删除集群中的某个redis 实例，需要在60秒内向整个集群的其他redis 实例发生forg","title":"Go context超时取消并发goroutine"},{"content":"1. 限流的作用 **限流定义：**限制「速率」，或从业务层限制「总数」，被限流的请求，直接进入「降级」fallback 流程(fallback与业务相关)；\n使用场景：\n应对突发流量，避免系统被压垮（全局限流和IP限流）。\n防刷，防止机器人脚本等频繁调用服务（userID限流和IP限流）\n对于应对突发流量避免系统压垮这个情景，可以在以下几方面做具体限流\n业务系统入口(入流量)，比如秒杀活动等系统做限流 系统依赖的外部系统(出流量)，比如某个渠道的支付QPS只有300，我们在访问它的服务对这个渠道做限流(防止雪崩) 核心子系统，比如交易 2. 限流的行为 在接口的请求数达到限流的条件时触发的操作，一般可进行以下行为。\n拒绝服务：把多出来的请求拒绝掉\n服务降级：关闭或是把后端服务做降级处理。这样可以让服务有足够的资源来处理更多的请求\n特权请求：资源不够了，我只能把有限的资源分给重要的用户\n延时处理：一般会有一个队列来缓冲大量的请求，这个队列如果满了，那么就只能拒绝用户了，如果这个队列中的任务超时了，也要返回系统繁忙的错误了\n弹性伸缩：用自动化运维的方式对相应的服务做自动化的伸缩\n3. 单机\u0026amp;分布式 本质上单机限流和分布式限流的区别其实就在于 “阈值” 存放的位置。单机限流就上面所说的算法直接在单台服务器上实现就好了，而往往我们的服务是集群部署的。因此需要多台机器协同提供限流功能。\n单节点限流 单实例限流，实现简单；依赖的资源如DB 无法被保护\n分布式限流 基于某种中间件(Redis)的限流方式，实现较复杂；但是能保护依赖资源不受流量冲击\n4.限流阈值 限流阈值的设置是一个难点，数值设置大了，超过服务器处理能力导致系统奔溃；数值设置小了，资源利用率无法最大化，并且影响用户体验。\n阈值设置，目前思路：\n上线前进行压测，确认整个业务系统的处理能力 灰度阈值，达到限流阈值时，服务只进行告警，开发和运维确认系统的资源情况，对阈值进行调整或者确认；等到对整个系统的处理能力比较清楚时，在打开开关进行真正的限流。 5. 限流实现算法 5.1 固定窗口计数器 将时间划分为多个窗口，在每个窗口内每有一次请求就将计数器加一；如果计数器超过了限制数量，则本窗口内所有的请求都被丢弃当时间到达下一个窗口时，计数器重置。\n优点：实现简单 缺点：不够平滑，并且存在“两倍配置速率”问题。\n两倍配置速率”问题： 考虑如下情况：限制 1 秒内最多通过 5 个请求，在第一个窗口的最后半秒内通过了 5 个请求，第二个窗口的前半秒内又通过了 5 个请求。这样看来就是在 1 秒内通过了 10 个请求。\n5.2 滑动窗口计数器 将时间划分为多个区间，在每个区间内每有一次请求就将计数器加一维持一个时间窗口，占据多个区间；每经过一个区间的时间，则抛弃最老的一个区间，并纳入最新的一个区间。如果当前窗口内区间的请求计数总和超过了限制数量，则本窗口内所有的请求都被丢弃。\n优点：避免双倍突发请求问题；时间区间的精度足够高时可以做到平滑 缺点：时间区间的精度越高，算法所需的空间容量就越大；依然存在突刺的情况\n5.3 漏桶 将每个请求视作\u0026quot;水滴\u0026quot;放入\u0026quot;漏桶\u0026quot;进行存储，“漏桶\u0026quot;以固定速率向外\u0026quot;漏\u0026quot;出请求来执行如果\u0026quot;漏桶\u0026quot;空了则停止\u0026quot;漏水”；如果\u0026quot;漏桶\u0026quot;满了则多余的\u0026quot;水滴\u0026quot;会被直接丢弃。\n漏桶算法多使用队列实现，服务的请求会存到队列中，服务的提供方则按照固定的速率从队列中取出请求并执行，过多的请求则放在队列中排队或直接拒绝。\n优点：解决了突刺现象 缺点：当短时间内有大量的突发请求时，即便此时服务器没有任何负载，每个请求也得在队列当中等一段时间才能被响应\n5.4 令牌桶 令牌以固定速率生成；生成的令牌放入令牌桶中存放，如果令牌桶满了则多余的令牌会直接丢弃。当请求到达时，会尝试从令牌桶中取令牌，取到了令牌的请求可以执行；如果桶空了，那么尝试取令牌的请求会被直接丢弃。\n优点：既平滑分布，又能够承受范围内的突发请求 缺点：每个请求必须从令牌桶取令牌，有性能要求\n6. 实现方案 6.1 Golang标准库限流器time/rate 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 // Wait is shorthand for WaitN(ctx, 1). func (lim *Limiter) Wait(ctx context.Context) (err error) { return lim.WaitN(ctx, 1) } // WaitN blocks until lim permits n events to happen. // It returns an error if n exceeds the Limiter\u0026#39;s burst size, the Context is // canceled, or the expected wait time exceeds the Context\u0026#39;s Deadline. // The burst limit is ignored if the rate limit is Inf. func (lim *Limiter) WaitN(ctx context.Context, n int) (err error) { lim.mu.Lock() burst := lim.burst limit := lim.limit lim.mu.Unlock() if n \u0026gt; burst \u0026amp;\u0026amp; limit != Inf { return fmt.Errorf(\u0026#34;rate: Wait(n=%d) exceeds limiter\u0026#39;s burst %d\u0026#34;, n, burst) } // Check if ctx is already cancelled select { case \u0026lt;-ctx.Done(): return ctx.Err() default: } // Determine wait limit now := time.Now() waitLimit := InfDuration if deadline, ok := ctx.Deadline(); ok { waitLimit = deadline.Sub(now) } // Reserve r := lim.reserveN(now, n, waitLimit) if !r.ok { return fmt.Errorf(\u0026#34;rate: Wait(n=%d) would exceed context deadline\u0026#34;, n) } // Wait if necessary delay := r.DelayFrom(now) if delay == 0 { return nil } t := time.NewTimer(delay) defer t.Stop() select { case \u0026lt;-t.C: // We can proceed. return nil case \u0026lt;-ctx.Done(): // Context was canceled before we could proceed. Cancel the // reservation, which may permit other events to proceed sooner. r.Cancel() return ctx.Err() } } Wait 实际上就是 WaitN(ctx,1)。\n​ 当使用 WaitN 方法消费 Token 时，如果此时桶内 Token 数组不足 (小于 N)，那么 WaitN 方法将会阻塞一段时间，直至 Token 满足条件。如果充足则直接返回。\n​ Wait 方法有一个 context 参数，我们可以设置 context 的 Deadline 或者 Timeout，来决定此次 Wait 的最长时间。\n​ 此方法实现, 并没有单独维护一个 Timer，而是采用了 lazyload 的方式，直到每次消费之前才根据时间差更新 Token 数目，而且也不是用 BlockingQueue 来存放 Token，而是仅仅通过计数的方式。\n6.2 Uber开源RateLimit 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // 根据初始化限流大小，生成每次请求见的时间间隔perRequest // 以及支持的最大松弛量maxSlack perRequest: time.Second / time.Duration(rate) maxSlack: -10 * time.Second / time.Duration(rate) // last表示上次结束时间， sleepFor表示要等待时间 newState.sleepFor += t.perRequest - now.Sub(oldState.last) // We shouldn\u0026#39;t allow sleepFor to get too negative, since it would mean that // a service that slowed down a lot for a short period of time would get // a much higher RPS following that. if newState.sleepFor \u0026lt; t.maxSlack { newState.sleepFor = t.maxSlack } if newState.sleepFor \u0026gt; 0 { newState.last = newState.last.Add(newState.sleepFor) } // sleep t.clock.Sleep(sleepFor) uber 在 Github 上开源了一套用于服务限流的 go 语言库 ratelimit, 该组件基于 Leaky Bucket(漏桶)实现，增加了一个maxSlack缓冲，相当于实现了令牌桶, 代码链接：https://github.com/golang/time/blob/master/rate/rate.go。\n采用原子操作+for的自旋操作来替代lock操作，这样做的目的是减少协程锁竞争。原理上是通过原子操作，计算出此请求需要等待的时间，然后sleep。此方案的劣势是只通过阻塞去限流，在请求量暴增的情况下，会全阻塞住，撑爆服务。可在此方案上增加超量拒绝功能。\n6.3 redis+lua 实现计数器 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 -- 获取调用脚本时传入的第一个 key 值（用作限流的 key） local key = KEYS[1] -- 获取调用脚本时传入的第一个参数值（限流大小） local limit = tonumber(ARGV[1]) -- 获取计数器的限速区间 TTL local ttl = tonumber(ARGV[2]) -- 获取当前流量大小 local curentLimit = tonumber(redis.call(\u0026#39;get\u0026#39;, key) or \u0026#34;0\u0026#34;) -- 是否超出限流 if curentLimit + 1 \u0026gt; limit then -- 返回 (拒绝) return 0 else -- 没有超出 value + 1 redis.call(\u0026#39;INCRBY\u0026#39;, key, 1) -- 如果 key 中保存的并发计数为 0，说明当前是一个新的时间窗口 -- 它的过期时间设置为窗口的过期时间 if (curentLimit == 0) then redis.call(\u0026#39;EXPIRE\u0026#39;, key, ttl) end -- 返回 (放行) return 1 end 通过 KEYS[1] 获取传入的 key 参数，为某个限流指标的 key 通过 ARGV[1] 获取传入的 limit 参数，为限流值 通过 ARGV[2] 获取限流区间 ttl 通过 redis.call，拿到 key 对应的值（默认为 0），接着与 limit 判断，如果超出表示该被限流；否则，使用 INCRBY 增加 1，未限流（需要处理初始化的情况，设置 TTL） 6.4 redis+lua 实现令牌 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 -- 获取调用脚本时传入的第一个key值（用作限流的 key） local key = KEYS[1] -- 获取调用脚本时传入的第一个参数值（限流频率） local rate = tonumber(ARGV[1]) -- 获取调用脚本时传入的第二个参数值（容量大小） local capacity = tonumber(ARGV[2]) -- 获取调用脚本时传入的第三个参数值（获取token数量） local needTokenNum = tonumber(ARGV[3]) --计算每次执行所需时间 local perRequest = 1/rate --此处获取当前时间，这里最好是获取redis服务器机器时间 local now = getNowTime() --获取最后一次执行时间 local last = tonumber(redis.pcall(\u0026#39;hget\u0026#39;, key, \u0026#39;last\u0026#39;)) or 0 if last \u0026lt; now - capacity * perRequest then last = now - capacity * perRequest end --第一个返回值，是否成功获取到token, 0表示成功，1表示失败 local returnResult = 1 --第二个返回值，需要等待的时间，配合第一个返回值 --获取token成功时\u0026lt;=0表示不需要等待，\u0026gt;0表示需要等待，返回给app可以让app等待重试 local sleepFor = perRequest * needTokenNum - (now - last) --sleepFor \u0026gt; 0 表示桶内已无令牌，需要等待 if sleepFor \u0026lt;= 0 then last += sleepFor returnResult = 0 redis.pcall(\u0026#39;hset\u0026#39;, key, \u0026#39;last\u0026#39;, last) --redis.pcall(\u0026#39;hset\u0026#39;, key, \u0026#39;rate\u0026#39;, rate) --redis.pcall(\u0026#39;hset\u0026#39;, key, \u0026#39;capacity\u0026#39;, capacity) local expire_t = capacity/rate + 1 redis.call(\u0026#34;EXPIRE\u0026#34;, key, expire_t) end return returnResult, sleepFor 以last作为最好一次执行时间，[last, now]时间区间/perRequest表示桶内剩余令牌数，为负值表示可以立即执行，为正值表示需要等待\n6.5 python单机限流实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 # -*- coding: utf-8 -*- import time from flask import Flask app = Flask(__name__) capacity = 10 # 桶容量 rate = 1 # 速率 每秒增加一个令牌 last_time = int(time.time()) # 上次访问时间 current_tokens = capacity # 当前令牌桶中令牌数量 def can_access(): global current_tokens global last_time now = int(time.time()) increase_tokens = (now - last_time) * rate current_tokens = min(capacity, current_tokens + increase_tokens) if current_tokens \u0026gt; 0: current_tokens -= 1 last_time = int(time.time()) return True else: return False @app.route(\u0026#39;/\u0026#39;) def tokens_bucket(): if not can_access(): return \u0026#39;速率超限制\u0026#39; return \u0026#39;Hello, 令牌桶!\u0026#39; if __name__ == \u0026#39;__main__\u0026#39;: app.run() 6.6 redis+python 分布式限流实现(装饰器) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 # -*- coding: utf-8 -*- import time from flask import Flask from flask import request from redis import Redis redis_client = Redis() app = Flask(__name__) current_tokens_key = \u0026#39;current_tokens\u0026#39; last_time_key = \u0026#39;last_time\u0026#39; def can_access(rate=1, capacity=5): \u0026#34;\u0026#34;\u0026#34; :param rate: 令牌桶添加速率，默认美妙1个 :param capacity: 令牌桶容量，默认5 :return: \u0026#34;\u0026#34;\u0026#34; def wrapper(func): def inner(*arg, **kwargs): func_name = func.__name__ ip = request.remote_addr hash_name = ip + func_name now = int(time.time()) current_tokens = redis_client.hget(hash_name, current_tokens_key) last_time = redis_client.hget(hash_name, last_time_key) current_tokens = int(current_tokens) if current_tokens else capacity last_time = int(last_time) if last_time else now increase_tokens = (now - last_time) * rate # 增加的令牌桶 current_tokens = min(capacity, current_tokens + increase_tokens) if current_tokens \u0026gt; 0: redis_client.hset(hash_name, current_tokens_key, current_tokens - 1) redis_client.hset(hash_name, last_time_key, int(time.time())) return func(*arg, **kwargs) else: return \u0026#39;当前ip:{}访问:{}接口速率超限制\u0026#39;.format(ip, func_name) return inner return wrapper @app.route(\u0026#39;/\u0026#39;) @can_access(rate=1, capacity=10) def tokens_bucket(): return \u0026#39;Hello, 令牌桶!\u0026#39; if __name__ == \u0026#39;__main__\u0026#39;: app.run() 6.7 Django Ratelimi django-ratelimit :https://django-ratelimit.readthedocs.io/en/stable/\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 # ip 每分钟5次请求，但是 block 请求 @ratelimit(key=\u0026#39;ip\u0026#39;, rate=\u0026#39;5/m\u0026#39;) def myview(request): # Will be true if the same IP makes more than 5 POST # requests/minute. was_limited = getattr(request, \u0026#39;limited\u0026#39;, False) return HttpResponse() # 限制 ip 每分钟5次请求， block 这个请求 @ratelimit(key=\u0026#39;ip\u0026#39;, rate=\u0026#39;5/m\u0026#39;, block=True) def myview(request): # If the same IP makes \u0026gt;5 reqs/min, will raise Ratelimited return HttpResponse() # 限制 post 中有 username 每分钟5次请求，另外请求方法只能为 GET ,POST @ratelimit(key=\u0026#39;post:username\u0026#39;, rate=\u0026#39;5/m\u0026#39;, method=[\u0026#39;GET\u0026#39;, \u0026#39;POST\u0026#39;]) def login(request): # If the same username is used \u0026gt;5 times/min, this will be True. # The `username` value will come from GET or POST, determined by the # request method. was_limited = getattr(request, \u0026#39;limited\u0026#39;, False) return HttpResponse() # 可以使用多种限制 @ratelimit(key=\u0026#39;post:username\u0026#39;, rate=\u0026#39;5/m\u0026#39;) @ratelimit(key=\u0026#39;post:password\u0026#39;, rate=\u0026#39;5/m\u0026#39;) def login(request): # Use multiple keys by stacking decorators. return HttpResponse() @ratelimit(key=\u0026#39;get:q\u0026#39;, rate=\u0026#39;5/m\u0026#39;) @ratelimit(key=\u0026#39;post:q\u0026#39;, rate=\u0026#39;5/m\u0026#39;) def search(request): # These two decorators combine to form one rate limit: the same search # query can only be tried 5 times a minute, regardless of the request # method (GET or POST) return HttpResponse() @ratelimit(key=\u0026#39;ip\u0026#39;, rate=\u0026#39;4/h\u0026#39;) def slow(request): # Allow 4 reqs/hour. return HttpResponse() # rate 可以自定义函数 rate = lambda r: None if request.user.is_authenticated() else \u0026#39;100/h\u0026#39; @ratelimit(key=\u0026#39;ip\u0026#39;, rate=rate) def skipif1(request): # Only rate limit anonymous requests return HttpResponse() # key 可以是 django 的 user ,如果没登录，则使用ip @ratelimit(key=\u0026#39;user_or_ip\u0026#39;, rate=\u0026#39;10/s\u0026#39;) @ratelimit(key=\u0026#39;user_or_ip\u0026#39;, rate=\u0026#39;100/m\u0026#39;) def burst_limit(request): # Implement a separate burst limit. return HttpResponse() @ratelimit(group=\u0026#39;expensive\u0026#39;, key=\u0026#39;user_or_ip\u0026#39;, rate=\u0026#39;10/h\u0026#39;) def expensive_view_a(request): return something_expensive() @ratelimit(group=\u0026#39;expensive\u0026#39;, key=\u0026#39;user_or_ip\u0026#39;, rate=\u0026#39;10/h\u0026#39;) def expensive_view_b(request): # Shares a counter with expensive_view_a return something_else_expensive() # key 可以为 header 里面的值 @ratelimit(key=\u0026#39;header:x-cluster-client-ip\u0026#39;) def post(request): # Uses the X-Cluster-Client-IP header value. return HttpResponse() # key 可以自定义函数 @ratelimit(key=lambda r: r.META.get(\u0026#39;HTTP_X_CLUSTER_CLIENT_IP\u0026#39;, r.META[\u0026#39;REMOTE_ADDR\u0026#39;]) def myview(request): # Use `X-Cluster-Client-IP` but fall back to REMOTE_ADDR. return HttpResponse() 7. 业界限流组件 Sentinel：阿里开源的限流框架 Sentinel 中的匀速排队限流策略，就采用了漏桶算法。\nNginx：Nginx 中的限流模块 limit_req_zone，采用了漏桶算法\nGuava客户端限流：Guava是一个客户端组件，在其多线程模块下提供了以RateLimiter为首的几个限流支持类。它只能对“当前”服务进行限流，即它不属于分布式限流的解决方案。\n参考链接 https://segmentfault.com/a/1190000023552181\nhttps://www.infoq.cn/article/ipxnuqwu3lgwxc8j7tzw\nhttps://confluence.shopee.io/pages/viewpage.action?pageId=254589331\nhttp://blog.bdaily.club/2016/09/29/django-%E9%98%B2%E7%88%AC%E8%99%AB%E5%AE%9E%E7%8E%B0/\n","permalink":"https://www.aiforagc.com/posts/limit_rate/","summary":"1. 限流的作用 **限流定义：**限制「速率」，或从业务层限制「总数」，被限流的请求，直接进入「降级」fallback 流程(fallback与业","title":"系统保护-限流"},{"content":"gin框架简介 Gin是一个基于Go语言的轻量级Web框架。它内置了常用的中间件，提供了更为简单、高效的API，能够快速搭建RESTful风格的Web服务。尽管Go语言本身提供了http库，但是其主要面向的是底层的网络编程，使用起来相对较为繁琐，而且不够高效。相比原生的http库，Gin提供了更为丰富的功能，如路由匹配、请求过滤、参数绑定、模板渲染等，能够大大提高开发效率和代码可维护性。因此，在开发Web服务时，使用Gin框架能够使开发更加高效和便捷。\n与Go语言的http库相比，Gin框架提供了更多路由匹配规则和参数。例如，Gin中可以使用gin.Context中的GET、POST、PUT、DELETE等方法定义不同的路由。在Gin中，还可以使用中间件对请求进行过滤和处理，例如定义一个中间件来验证请求中是否包含指定的Header。Gin中还可以使用gin.Context中的Bind或BindJSON方法将请求体中的参数绑定到指定的结构体或变量中，使用HTML方法来渲染HTML模板等。因此，Gin框架相比Go语言的http库，提供了更加丰富、灵活的功能。\n使用gin实现的Web服务器demo 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 package main import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) func main() { // 创建一个默认的gin引擎 r := gin.Default() // 定义一个GET请求的路由，并返回一个字符串 r.GET(\u0026#34;/\u0026#34;, func(c *gin.Context) { c.String(http.StatusOK, \u0026#34;Hello, World!\u0026#34;) }) // 定义一个POST请求的路由，并返回请求中的参数 r.POST(\u0026#34;/post\u0026#34;, func(c *gin.Context) { name := c.PostForm(\u0026#34;name\u0026#34;) age := c.PostForm(\u0026#34;age\u0026#34;) c.JSON(http.StatusOK, gin.H{ \u0026#34;name\u0026#34;: name, \u0026#34;age\u0026#34;: age, }) }) // 启动Web服务器，默认监听8080端口 r.Run() } gin提供的核心功能 路由匹配 在 Gin 中，可以使用 gin.Context 中的 GET、POST、PUT、DELETE 等方法定义不同的路由，例如：\n1 2 3 4 5 6 router := gin.Default() router.GET(\u0026#34;/hello\u0026#34;, func(c *gin.Context) { c.JSON(http.StatusOK, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;hello world\u0026#34;, }) }) 上述代码中，我们定义了一个 GET 请求，路由路径为 /hello，对应的处理函数中返回了一个 JSON 格式的数据。\n请求过滤 Gin 中可以使用中间件（middleware）对请求进行过滤和处理。例如，下面的代码展示了如何定义一个中间件来验证请求中是否包含指定的 Header。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func ValidateHeader(header string) gin.HandlerFunc { return func(c *gin.Context) { if value := c.GetHeader(header); value == \u0026#34;\u0026#34; { c.AbortWithStatusJSON(http.StatusBadRequest, gin.H{ \u0026#34;message\u0026#34;: fmt.Sprintf(\u0026#34;missing %s header\u0026#34;, header), }) } else { c.Next() } } } router := gin.Default() router.Use(ValidateHeader(\u0026#34;X-Auth-Token\u0026#34;)) router.GET(\u0026#34;/hello\u0026#34;, func(c *gin.Context) { c.JSON(http.StatusOK, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;hello world\u0026#34;, }) }) 上述代码中，我们定义了一个名为 ValidateHeader 的中间件，它检查请求头中是否包含 X-Auth-Token，如果不包含则返回错误响应，否则继续执行后续的请求处理函数。\n参数绑定 在 Gin 中，可以使用 gin.Context 中的 Bind 或 BindJSON 方法将请求体中的参数绑定到指定的结构体或变量中。例如：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 type User struct { Name string `json:\u0026#34;name\u0026#34;` Age int `json:\u0026#34;age\u0026#34;` } router := gin.Default() router.POST(\u0026#34;/user\u0026#34;, func(c *gin.Context) { var user User if err := c.BindJSON(\u0026amp;user); err != nil { c.AbortWithStatusJSON(http.StatusBadRequest, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;invalid request body\u0026#34;, }) return } // do something with user c.JSON(http.StatusOK, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;user created\u0026#34;, \u0026#34;user\u0026#34;: user, }) }) 上述代码中，我们定义了一个名为 User 的结构体，并将其作为请求处理函数的参数。在请求处理函数中，我们使用 BindJSON 方法将请求体中的参数绑定到 user 变量中。\n模板渲染 在 Gin 中，可以使用 gin.Context 中的 HTML 方法来渲染 HTML 模板。例如：\n1 2 3 4 5 6 7 8 router := gin.Default() router.LoadHTMLGlob(\u0026#34;templates/*.html\u0026#34;) router.GET(\u0026#34;/hello\u0026#34;, func(c *gin.Context) { c.HTML(http.StatusOK, \u0026#34;hello.html\u0026#34;, gin.H{ \u0026#34;message\u0026#34;: \u0026#34;hello world\u0026#34;, }) }) 上述代码中，我们使用 LoadHTMLGlob 方法加载了 templates 目录下的所有 HTML 模板，然后在\n与 go http的路由功能差别 gin 和 go http 都可以实现路由功能，但是 gin 对路由功能进行了增强，提供了更多的路由匹配规则和参数绑定的功能。\n举个例子，假设有一个处理 GET 请求的路由：\n1 2 3 func handleGetRequest(w http.ResponseWriter, r *http.Request) { // ... } http.HandleFunc(\u0026quot;/users\u0026quot;, handleGetRequest) 这个路由会匹配所有的 GET 请求，例如：\n1 2 3 GET /users GET /users?id=123 GET /users/123 但是它只能从 URL 查询参数中获取参数值，如果要从 URL 路径中获取参数值，需要自己解析 URL。而使用 gin，可以轻松地实现从 URL 路径中获取参数值，并且支持多种路由匹配规则：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 func handleGetRequest(c *gin.Context) { id := c.Param(\u0026#34;id\u0026#34;) // ... } router := gin.Default() // 匹配 GET /users 或者 GET /users?id=123 router.GET(\u0026#34;/users\u0026#34;, handleGetRequest) // 匹配 GET /users/123 router.GET(\u0026#34;/users/:id\u0026#34;, handleGetRequest) // 匹配 GET /users/123/orders router.GET(\u0026#34;/users/:id/orders\u0026#34;, handleGetRequest) 在这个例子中，使用了 router.GET 方法来定义路由，支持从 URL 路径中获取参数值，并且支持多种路由匹配规则，如 :id 和 /*any。同时，参数绑定也更加方便，可以使用 c.Bind 和 c.ShouldBind 等方法，自动将请求参数绑定到结构体中。\n","permalink":"https://www.aiforagc.com/posts/go_gin/","summary":"gin框架简介 Gin是一个基于Go语言的轻量级Web框架。它内置了常用的中间件，提供了更为简单、高效的API，能够快速搭建RESTful风格","title":"Gin：轻量级 Go Web 框架"},{"content":"跳表 跳表（Skip List）是一种基于随机化的数据结构，它通过多层索引来加速数据的查找，可以看作是一种高效的平衡树结构。跳表的插入、删除和查找操作的平均时间复杂度都是O(log n)，比起平衡树的实现要简单很多。\n跳表的结构类似于链表，每个节点除了保存元素值外，还包含一个指针数组，分别指向对应层次的下一个节点。这种多级指针的设计，使得跳表可以跨越多个节点进行快速搜索，同时保证跳表结构的高效性和简洁性。\n跳表的每一层都是一个有序链表，第0层是原始数据链表，每一层都是下一层的子集。比如第1层链表中的元素是第0层链表中的元素隔一个节点而成，第2层链表中的元素是第1层链表中的元素隔一个节点而成，以此类推。跳表的最高层是一个只有一个元素的链表。 跳表支持范围查询、插入、删除、查找、合并等高级操作，非常适合用于实现高效的搜索引擎、缓存、排序等应用场景。\n跳表在redis 应用 Redis中的有序集合（Sorted Set）实际上是基于跳表（Skip List）实现的。在Redis中，每个有序集合都包含一个跳表（Skip List），跳表的每个节点都存储了元素的成员值和score值，以及指向其他节点的指针。在有序集合中，元素按照score值从小到大排序，跳表中每个节点都是按照score值从小到大排序的。\n有序集合中的节点按照一定的概率随机生成跳表的多级索引。例如，对于一个有序集合，它的底层节点的个数为n，索引层数为h，则顶层索引只包含一个节点，底层索引包含n个节点。对于每个节点，生成的索引层数都是随机的，并且是服从某个概率分布的。一般情况下，索引层数在2到4之间比较常见，这样可以兼顾查找效率和内存占用。由于有序集合中的元素是按照score值排序的，因此可以利用跳表的高效性实现一些高级的操作，例如范围查询、排名和求交、并、差等集合操作。\nRedis使用跳表而不是平衡树的原因\n跳表的实现比树简单，不需要考虑平衡问题。 跳表的插入和删除操作比树快，只需要修改相邻节点的指针。 跳表可以方便地实现范围查询和排名查询，而树需要额外的遍历操作。 跳表占用的内存空间比树小，因为跳表的节点数目和层数都是随机生成的。 redis 跳表实现 redis跳表 结构定义在server.h中，操作实现在t_zset.c中。\n数据结构定义 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 //server.h #define ZSKIPLIST_MAXLEVEL 32 /* Should be enough for 2^64 elements */ typedef struct zskiplistNode { sds ele; double score; struct zskiplistNode *backward; //指向前一个节点(最底层) struct zskiplistLevel { struct zskiplistNode *forward; // 指向同一层下个节点 // 到同一层节点下个节点 有多少个数据节点 // 用于排名范围查询 unsigned long span; } level[]; } zskiplistNode; typedef struct zskiplist { struct zskiplistNode *header, *tail; // 指向头尾节点 unsigned long length; // 跳表节点个数 int level; // 跳表当前拥有节点的最高层次 } zskiplist; typedef struct zset { dict *dict; zskiplist *zsl; // 用跳表实现 score 和 排名 访问查询 } zset; 跳表节点创建\u0026amp;释放 创建节点指定 key 、 score 和 节点level(层高)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 /* Create a skiplist node with the specified number of levels. * The SDS string \u0026#39;ele\u0026#39; is referenced by the node after the call. */ zskiplistNode *zslCreateNode(int level, double score, sds ele) { zskiplistNode *zn = zmalloc(sizeof(*zn)+level*sizeof(struct zskiplistLevel)); zn-\u0026gt;score = score; zn-\u0026gt;ele = ele; return zn; } /* Free the specified skiplist node. The referenced SDS string representation * of the element is freed too, unless node-\u0026gt;ele is set to NULL before calling * this function. */ void zslFreeNode(zskiplistNode *node) { sdsfree(node-\u0026gt;ele); zfree(node); } 跳表初始化 分配内存，创建head节点，并做相关初始化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /* Create a new skiplist. */ zskiplist *zslCreate(void) { int j; zskiplist *zsl; zsl = zmalloc(sizeof(*zsl)); zsl-\u0026gt;level = 1; zsl-\u0026gt;length = 0; // ZSKIPLIST_MAXLEVEL 为 32 // 创建头结点 zsl-\u0026gt;header = zslCreateNode(ZSKIPLIST_MAXLEVEL,0,NULL); for (j = 0; j \u0026lt; ZSKIPLIST_MAXLEVEL; j++) { zsl-\u0026gt;header-\u0026gt;level[j].forward = NULL; zsl-\u0026gt;header-\u0026gt;level[j].span = 0; } zsl-\u0026gt;header-\u0026gt;backward = NULL; zsl-\u0026gt;tail = NULL; return zsl; } 插入节点 根据score寻找每层次前一个节点 决定插入节点层数，分配节点 设置各层前置节点指针 和插入节点指针 设置前置节点span 和插入节点span 设置插入节点之指前一个数据节点(最底层) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 /* Insert a new node in the skiplist. Assumes the element does not already * exist (up to the caller to enforce that). The skiplist takes ownership * of the passed SDS string \u0026#39;ele\u0026#39;. */ zskiplistNode *zslInsert(zskiplist *zsl, double score, sds ele) { zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; unsigned int rank[ZSKIPLIST_MAXLEVEL]; int i, level; // 根据score找到每一层的前一个节点 serverAssert(!isnan(score)); x = zsl-\u0026gt;header; for (i = zsl-\u0026gt;level-1; i \u0026gt;= 0; i--) { /* store rank that is crossed to reach the insert position */ rank[i] = i == (zsl-\u0026gt;level-1) ? 0 : rank[i+1]; while (x-\u0026gt;level[i].forward \u0026amp;\u0026amp; (x-\u0026gt;level[i].forward-\u0026gt;score \u0026lt; score || (x-\u0026gt;level[i].forward-\u0026gt;score == score \u0026amp;\u0026amp; sdscmp(x-\u0026gt;level[i].forward-\u0026gt;ele,ele) \u0026lt; 0))) { rank[i] += x-\u0026gt;level[i].span; //第i层 计算遍历到当前节点的排名 x = x-\u0026gt;level[i].forward; } update[i] = x; } /* we assume the element is not already inside, since we allow duplicated * scores, reinserting the same element should never happen since the * caller of zslInsert() should test in the hash table if the element is * already inside or not. */ //随机对当前插入节点 产生一个层数 // 层数按1/4 产生，也就是第二层数量是第一层(最底层)的1/4 level = zslRandomLevel(); //高于当前节点 最高层数 的层次前一个节点是head if (level \u0026gt; zsl-\u0026gt;level) { for (i = zsl-\u0026gt;level; i \u0026lt; level; i++) { rank[i] = 0; update[i] = zsl-\u0026gt;header; update[i]-\u0026gt;level[i].span = zsl-\u0026gt;length; } zsl-\u0026gt;level = level; } // 创建新节点 x = zslCreateNode(level,score,ele); for (i = 0; i \u0026lt; level; i++) { // 处理每一层链表指针指向 x-\u0026gt;level[i].forward = update[i]-\u0026gt;level[i].forward; update[i]-\u0026gt;level[i].forward = x; // 更新前一个节点的span(因为中间插入了节点) /* update span covered by update[i] as x is inserted here */ x-\u0026gt;level[i].span = update[i]-\u0026gt;level[i].span - (rank[0] - rank[i]); // 设置插入节点的span update[i]-\u0026gt;level[i].span = (rank[0] - rank[i]) + 1; } // 比插入节点层数高的 前一个节点增加他们的span(插入新节点) /* increment span for untouched levels */ for (i = level; i \u0026lt; zsl-\u0026gt;level; i++) { update[i]-\u0026gt;level[i].span++; } //指向前一个节点(最底层) x-\u0026gt;backward = (update[0] == zsl-\u0026gt;header) ? NULL : update[0]; //处理下一个节点backward指向 新插入节点 if (x-\u0026gt;level[0].forward) x-\u0026gt;level[0].forward-\u0026gt;backward = x; else zsl-\u0026gt;tail = x; zsl-\u0026gt;length++; return x; } 删除节点 查找要被删除元素的各个层次前一个节点 各个层次前一个节点直接指向 被删除节点后置节点 正确设置各个层次前一个节点span值(因为删除掉一个节点) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 /* Internal function used by zslDelete, zslDeleteRangeByScore and * zslDeleteRangeByRank. */ void zslDeleteNode(zskiplist *zsl, zskiplistNode *x, zskiplistNode **update) { int i; for (i = 0; i \u0026lt; zsl-\u0026gt;level; i++) { if (update[i]-\u0026gt;level[i].forward == x) { update[i]-\u0026gt;level[i].span += x-\u0026gt;level[i].span - 1; update[i]-\u0026gt;level[i].forward = x-\u0026gt;level[i].forward; } else { update[i]-\u0026gt;level[i].span -= 1; } } if (x-\u0026gt;level[0].forward) { x-\u0026gt;level[0].forward-\u0026gt;backward = x-\u0026gt;backward; } else { zsl-\u0026gt;tail = x-\u0026gt;backward; } while(zsl-\u0026gt;level \u0026gt; 1 \u0026amp;\u0026amp; zsl-\u0026gt;header-\u0026gt;level[zsl-\u0026gt;level-1].forward == NULL) zsl-\u0026gt;level--; zsl-\u0026gt;length--; } /* Delete an element with matching score/element from the skiplist. * The function returns 1 if the node was found and deleted, otherwise * 0 is returned. * * If \u0026#39;node\u0026#39; is NULL the deleted node is freed by zslFreeNode(), otherwise * it is not freed (but just unlinked) and *node is set to the node pointer, * so that it is possible for the caller to reuse the node (including the * referenced SDS string at node-\u0026gt;ele). */ int zslDelete(zskiplist *zsl, double score, sds ele, zskiplistNode **node) { zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; int i; // 查找要被删除元素的各个层次前一个节点 x = zsl-\u0026gt;header; for (i = zsl-\u0026gt;level-1; i \u0026gt;= 0; i--) { while (x-\u0026gt;level[i].forward \u0026amp;\u0026amp; (x-\u0026gt;level[i].forward-\u0026gt;score \u0026lt; score || (x-\u0026gt;level[i].forward-\u0026gt;score == score \u0026amp;\u0026amp; sdscmp(x-\u0026gt;level[i].forward-\u0026gt;ele,ele) \u0026lt; 0))) { x = x-\u0026gt;level[i].forward; } update[i] = x; } /* We may have multiple elements with the same score, what we need * is to find the element with both the right score and object. */ x = x-\u0026gt;level[0].forward; if (x \u0026amp;\u0026amp; score == x-\u0026gt;score \u0026amp;\u0026amp; sdscmp(x-\u0026gt;ele,ele) == 0) { // 各个层次前一个节点直接指向 被删除节点后置节点 // 正确设置各个层次前一个节点span值(因为删除掉一个节点) zslDeleteNode(zsl, x, update); if (!node) zslFreeNode(x); else *node = x; return 1; } return 0; /* not found */ } 更新节点Score 查找要被删除元素的各个层次前一个节点 依据底层前后节点判断节点更新score后如果不需要重新排序，直接更新score返回 需要调整顺序，先摘除(删除)节点,再重新插入 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 /* Update the score of an element inside the sorted set skiplist. * Note that the element must exist and must match \u0026#39;score\u0026#39;. * This function does not update the score in the hash table side, the * caller should take care of it. * * Note that this function attempts to just update the node, in case after * the score update, the node would be exactly at the same position. * Otherwise the skiplist is modified by removing and re-adding a new * element, which is more costly. * * The function returns the updated element skiplist node pointer. */ zskiplistNode *zslUpdateScore(zskiplist *zsl, double curscore, sds ele, double newscore) { zskiplistNode *update[ZSKIPLIST_MAXLEVEL], *x; int i; // 查找要被删除元素的各个层次前一个节点 /* We need to seek to element to update to start: this is useful anyway, * we\u0026#39;ll have to update or remove it. */ x = zsl-\u0026gt;header; for (i = zsl-\u0026gt;level-1; i \u0026gt;= 0; i--) { while (x-\u0026gt;level[i].forward \u0026amp;\u0026amp; (x-\u0026gt;level[i].forward-\u0026gt;score \u0026lt; curscore || (x-\u0026gt;level[i].forward-\u0026gt;score == curscore \u0026amp;\u0026amp; sdscmp(x-\u0026gt;level[i].forward-\u0026gt;ele,ele) \u0026lt; 0))) { x = x-\u0026gt;level[i].forward; } update[i] = x; } /* Jump to our element: note that this function assumes that the * element with the matching score exists. */ x = x-\u0026gt;level[0].forward; serverAssert(x \u0026amp;\u0026amp; curscore == x-\u0026gt;score \u0026amp;\u0026amp; sdscmp(x-\u0026gt;ele,ele) == 0); // 依据底层前后节点判断节点更新score后如果不需要重新排序，直接更新score返回 /* If the node, after the score update, would be still exactly * at the same position, we can just update the score without * actually removing and re-inserting the element in the skiplist. */ if ((x-\u0026gt;backward == NULL || x-\u0026gt;backward-\u0026gt;score \u0026lt; newscore) \u0026amp;\u0026amp; (x-\u0026gt;level[0].forward == NULL || x-\u0026gt;level[0].forward-\u0026gt;score \u0026gt; newscore)) { x-\u0026gt;score = newscore; return x; } // 需要调整顺序，先摘除(删除)节点,再重新插入 /* No way to reuse the old node: we need to remove and insert a new * one at a different place. */ zslDeleteNode(zsl, x, update); zskiplistNode *newnode = zslInsert(zsl,newscore,x-\u0026gt;ele); /* We reused the old node x-\u0026gt;ele SDS string, free the node now * since zslInsert created a new one. */ x-\u0026gt;ele = NULL; zslFreeNode(x); return newnode; } 排名查询 获取key对应排名 根据查找节点score和后置节点score 大小 \u0026amp;\u0026amp; 根据查找节点key和后置节点key 逐层确定元素\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 /* Find the rank for an element by both score and key. * Returns 0 when the element cannot be found, rank otherwise. * Note that the rank is 1-based due to the span of zsl-\u0026gt;header to the * first element. */ unsigned long zslGetRank(zskiplist *zsl, double score, sds ele) { zskiplistNode *x; unsigned long rank = 0; int i; // 根据查找节点score和后置节点score 大小 // 根据查找节点key和后置节点key // 逐层确定元素 x = zsl-\u0026gt;header; for (i = zsl-\u0026gt;level-1; i \u0026gt;= 0; i--) { while (x-\u0026gt;level[i].forward \u0026amp;\u0026amp; (x-\u0026gt;level[i].forward-\u0026gt;score \u0026lt; score || (x-\u0026gt;level[i].forward-\u0026gt;score == score \u0026amp;\u0026amp; sdscmp(x-\u0026gt;level[i].forward-\u0026gt;ele,ele) \u0026lt;= 0))) { rank += x-\u0026gt;level[i].span; x = x-\u0026gt;level[i].forward; } /* x might be equal to zsl-\u0026gt;header, so test if obj is non-NULL */ if (x-\u0026gt;ele \u0026amp;\u0026amp; sdscmp(x-\u0026gt;ele,ele) == 0) { return rank; } } return 0; } 获取排名对应节点 根据每层span 累加，快速定位到对应排名的节点 获取排名后直接用底层指针向后遍历就可以获取一段排名范围内的元素 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 /* Finds an element by its rank. The rank argument needs to be 1-based. */ zskiplistNode* zslGetElementByRank(zskiplist *zsl, unsigned long rank) { zskiplistNode *x; unsigned long traversed = 0; int i; // 根据每层span 累加，快速定位到对应排名的节点 x = zsl-\u0026gt;header; for (i = zsl-\u0026gt;level-1; i \u0026gt;= 0; i--) { while (x-\u0026gt;level[i].forward \u0026amp;\u0026amp; (traversed + x-\u0026gt;level[i].span) \u0026lt;= rank) { traversed += x-\u0026gt;level[i].span; x = x-\u0026gt;level[i].forward; } if (traversed == rank) { return x; } } return NULL; } score 查询 获取score范围启始(末尾)节点：\n判断是否超过跳表 覆盖的分数范围，直接返回空 根据 每层节点score 与 查找的最小(最大)score值，逐步确定元素 判断找到的元素是否超过 查找访问的最大(最小)score，如果是返回空 返回查找到节点 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 /* Struct to hold an inclusive/exclusive range spec by score comparison. */ typedef struct { double min, max; int minex, maxex; /* are min or max exclusive? */ } zrangespec; /* Returns if there is a part of the zset is in range. */ int zslIsInRange(zskiplist *zsl, zrangespec *range) { zskiplistNode *x; //取第一个元素(最小值) 和 最后一个元素(最大值)，判断查找的score 范围是否与跳表存在交集 /* Test for ranges that will always be empty. */ if (range-\u0026gt;min \u0026gt; range-\u0026gt;max || (range-\u0026gt;min == range-\u0026gt;max \u0026amp;\u0026amp; (range-\u0026gt;minex || range-\u0026gt;maxex))) return 0; x = zsl-\u0026gt;tail; if (x == NULL || !zslValueGteMin(x-\u0026gt;score,range)) return 0; x = zsl-\u0026gt;header-\u0026gt;level[0].forward; if (x == NULL || !zslValueLteMax(x-\u0026gt;score,range)) return 0; return 1; } /* Find the first node that is contained in the specified range. * Returns NULL when no element is contained in the range. */ zskiplistNode *zslFirstInRange(zskiplist *zsl, zrangespec *range) { zskiplistNode *x; int i; // 判断是否超过跳表 覆盖的分数范围 /* If everything is out of range, return early. */ if (!zslIsInRange(zsl,range)) return NULL; // 根据 每层节点score 与 查找的最小score值，逐步确定元素 x = zsl-\u0026gt;header; for (i = zsl-\u0026gt;level-1; i \u0026gt;= 0; i--) { /* Go forward while *OUT* of range. */ while (x-\u0026gt;level[i].forward \u0026amp;\u0026amp; !zslValueGteMin(x-\u0026gt;level[i].forward-\u0026gt;score,range)) x = x-\u0026gt;level[i].forward; } /* This is an inner range, so the next node cannot be NULL. */ x = x-\u0026gt;level[0].forward; serverAssert(x != NULL); // 判断找到的元素是否超过 查找访问的最大score /* Check if score \u0026lt;= max. */ if (!zslValueLteMax(x-\u0026gt;score,range)) return NULL; return x; } /* Find the last node that is contained in the specified range. * Returns NULL when no element is contained in the range. */ zskiplistNode *zslLastInRange(zskiplist *zsl, zrangespec *range) { zskiplistNode *x; int i; // 判断是否超过跳表 覆盖的分数范围 /* If everything is out of range, return early. */ if (!zslIsInRange(zsl,range)) return NULL; // 根据 每层节点score 与 查找的最大score值，逐步确定元素 x = zsl-\u0026gt;header; for (i = zsl-\u0026gt;level-1; i \u0026gt;= 0; i--) { /* Go forward while *IN* range. */ while (x-\u0026gt;level[i].forward \u0026amp;\u0026amp; zslValueLteMax(x-\u0026gt;level[i].forward-\u0026gt;score,range)) x = x-\u0026gt;level[i].forward; } /* This is an inner range, so this node cannot be NULL. */ serverAssert(x != NULL); // 判断找到的元素是否超过 查找访问的最小score /* Check if score \u0026gt;= min. */ if (!zslValueGteMin(x-\u0026gt;score,range)) return NULL; return x; } ","permalink":"https://www.aiforagc.com/posts/redis_zset/","summary":"跳表 跳表（Skip List）是一种基于随机化的数据结构，它通过多层索引来加速数据的查找，可以看作是一种高效的平衡树结构。跳表的插入、删除和查","title":"Redis 实现高效有序集合(zset)：跳表源码分析"},{"content":"作为两种常见的编程语言，Go和C++有着显著的不同之处。下面将从语言设计和哲学、语法和表达能力、并发编程、内存管理、性能、包管理、其他特性、应用领域等方面进行比较和分析。\n语言设计和哲学 Go的设计和哲学 Go是由Google公司开发的一门编程语言，于2009年首次公开发布。Go的设计哲学强调简单、高效、安全和可读性。Go借鉴了C语言和Python的一些特性，旨在提供一种适合现代计算机硬件和多核处理器的语言。Go的设计理念是让程序员专注于解决问题，而不是陷入语言特性的细节中。\nC++的设计和哲学 C++是由Bjarne Stroustrup于1983年开发的一门编程语言，旨在扩展C语言的功能和特性。C++的设计哲学强调性能、灵活性和底层控制。C++是一门多范式编程语言，支持面向对象编程、泛型编程、函数式编程等多种编程风格。C++的设计理念是提供一种高效的语言，可以在不损失控制力和灵活性的情况下，实现各种应用领域的需求。\n语法和表达能力 Go的语法和表达能力 Go的语法非常简洁，支持垃圾回收和协程等高级特性。Go的语言特性鼓励使用简洁、清晰的代码，注重可读性和可维护性。Go的函数可以作为一等公民，可以像其他类型一样传递和赋值。Go也支持匿名函数和闭包等特性，使得代码更加灵活和简洁。\nC++的语法和表达能力 C++的语法比较复杂，支持多种编程风格。C++可以使用类、继承和多态等特性，实现面向对象编程。C++还支持模板和泛型编程，可以实现高度抽象和通用的代码。C++的表达能力很强，可以使用各种运算符、指针和引用等特性，实现底层控制和高性能计算。\n并发编程 Go的并发编程 Go在语言层面上原生支持协程和通道，提供了很好的并发编程支持。通过使用通道，可以很方便地实现数据共享和协作。Go的并发编程模型采用了CSP（Communicating Sequential Processes）模型，使得并发编程更加简单和安全。此外，Go的调度器使用了一种称为“goroutine”的轻量级线程，可以轻松创建数千个goroutine，而不会导致系统负载过重。\nC++的并发编程 C++的并发编程需要依赖于线程库和同步原语等特性，需要程序员自己管理线程和数据同步。C++的并发编程模型采用了Pthreads和C++11的标准线程库等机制，需要手动管理线程和同步机制。C++的并发编程需要程序员更加关注细节和安全性，需要仔细处理共享数据和竞争条件等问题。\n内存管理 Go的内存管理 Go的内存管理使用了垃圾回收机制，程序员无需手动分配和释放内存。Go的垃圾回收器使用了并发标记-清除算法，可以在运行时自动回收不再使用的内存。此外，Go的内存管理也支持指针和引用等特性，可以实现底层控制和高效的数据结构操作。\nC++的内存管理 C++的内存管理需要程序员手动分配和释放内存，使用了new和delete等关键字。C++的内存管理也支持指针和引用等特性，可以实现底层控制和高效的数据结构操作。C++的内存管理需要程序员更加关注细节和安全性，需要仔细处理内存泄漏和悬垂指针等问题。\n性能 Go的性能 Go的性能表现优秀，可以与C++等底层语言相媲美。Go的编译器和运行时都被优化为了快速和高效的执行，而且Go的并发编程特性也使得程序可以更加充分地利用多核处理器和分布式计算资源。\nC++的性能 C++是一门高性能的语言，可以实现底层控制和高效的计算。C++的编译器和运行时都被优化为了快速和高效的执行，而且C++也支持多线程和SIMD指令等特性，可以进一步提高性能。\n包管理 Go的包管理 Go的包管理系统非常简单，使用go get命令可以轻松地下载和安装依赖包。Go的包管理系统还支持版本控制和依赖管理等特性，可以方便地管理各种依赖关系。\nC++的包管理 C++的包管理比较困难，需要手动下载和编译依赖包。C++的包管理还存在依赖管理和版本控制等问题，需要程序员自己管理。C++的包管理可以使用CMake等工具来管理依赖关系，但需要程序员自己编写CMake脚本等文件。\n其他特性 Go的其他特性 Go还有一些其他特性，例如内置的字符串、切片和映射等数据类型，可以方便地进行数据处理和操作。Go还支持自定义类型和接口等特性，可以实现面向对象编程和抽象化设计等。Go的标准库也非常丰富，提供了各种常用的功能和组件，例如网络编程、加密和解压等操作。\nC++的其他特性 C++也有很多其他特性，例如模板和泛型编程、函数重载和多态性等。C++的标准库也非常丰富，提供了各种常用的功能和组件，例如STL容器、算法和IO等操作。C++还支持底层控制和内嵌汇编等特性，可以实现高效的计算和系统编程。\n应用领域 Go的应用领域 Go适合于开发网络服务、分布式系统和云原生应用等场景。Go的并发编程特性和轻量级线程模型可以方便地处理高并发和分布式计算任务。Go的内置网络库和标准库也提供了丰富的网络编程功能和组件，可以快速开发各种网络服务和应用。\nC++的应用领域 C++适合于开发高性能和底层系统的应用。C++的底层控制和内存管理等特性可以实现高效的计算和系统编程。C++还支持多线程和并行计算等特性，可以方便地处理高性能和并发场景。C++还是很多游戏和图形应用的主要编程语言，例如3D游戏和图像处理等领域。\n结论 综上所述，Go和C++是两门非常不同的编程语言，各自有自己的设计哲学、语法和表达能力、并发编程、内存管理、性能、包管理和其他特性等方面的特点和优劣。Go适合于开发网络服务、分布式系统和云原生应用等场景，而C++适合于开发高性能和底层系统的应用。选择哪一门编程语言取决于具体的应用场景和需求，需要程序员综合考虑各种因素来做出最佳选择。\n","permalink":"https://www.aiforagc.com/posts/go_comp_cplus/","summary":"作为两种常见的编程语言，Go和C++有着显著的不同之处。下面将从语言设计和哲学、语法和表达能力、并发编程、内存管理、性能、包管理、其他特性、","title":"从语言设计到应用领域：比较Go和C++的异同"},{"content":"作者最近在研究和k8s相关的项目，为了学习k8s，在mac上安装了Minikube。Minikube是一款单机搭建和管理Kubernetes集群的工具。\n1. 安装软件 mac如果安装了 Homebrew，直接执行以下命令安装minikube\n1 brew install minikube mac没有安装Homebrew,需要到官网下载选择系统配置，生成对应的curl命令和install 命令进行安装 1 2 curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-darwin-amd64 sudo install minikube-darwin-amd64 /usr/local/bin/minikube 2. 启动Minikube 启动单node的minikube\n1 minikube start 如果想启动3个node minikube使用以下命令\n1 minikube start -n 3 3. 检查Kubernetes集群 检查node节点个数\n1 minikube node list 检查系统相关pod是否正常运行\n1 minikube kubectl -- get po -A 为了方便使用，我们为minikube kubectl 设置别名\n1 alias kubectl=\u0026#34;minikube kubectl --\u0026#34; 刚启动时可能一些服务（例如存储提供者）可能还没有处于“运行”状态。这是集群启动过程中的正常情况。要了解集群状态的更多信息，minikube集成了Kubernetes的Dashboard，可以图形化的观察或者配置整个集群的运行状态\n1 minikube dashboard 4. 部署Redis 本节将在minikube中部署redis实例。\n4.1 创建Redis配置 假设 我们需要配置redis运行配置, 在物理机部署时我们都是创建一个文件并且设置好配置内容，然后启动redis。\n在k8s中我们通过configmap来配置内容，并且通过volume 将configmap 映射到redis实例对应的pod 相关路径下，这样就可以配置redis的运行参数\n首先来看下redis 配置的configmap yaml文件example-redis-config.yaml\n1 2 3 4 5 6 7 8 apiVersion: v1 kind: ConfigMap metadata: name: example-redis-config data: redis-config: | maxmemory 2mb maxmemory-policy allkeys-lru 创建configmap:\n1 kubectl apply -f example-redis-config.yaml 确认configmap 内容\n1 kubectl describe configmap example-redis-config 命令输出如下：\n1 2 3 4 5 6 7 8 9 10 11 Name: example-redis-config Namespace: default Labels: \u0026lt;none\u0026gt; Annotations: \u0026lt;none\u0026gt; Data ==== redis-config: ---- maxmemory 2mb maxmemory-policy allkeys-lru 4.3 创建Redis实例 下面是redis实例的pod yaml 文件redis-pod.yaml:\nconfigmap example-redis-config挂载到pod的/redis-master目录下 pod 启动命令是 redis-server \u0026ldquo;/redis-master/redis.conf\u0026rdquo;，正好读取configmap内容作为配置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 apiVersion: v1 kind: Pod metadata: name: redis spec: containers: - name: redis image: redis:5.0.4 command: - redis-server - \u0026#34;/redis-master/redis.conf\u0026#34; env: - name: MASTER value: \u0026#34;true\u0026#34; ports: - containerPort: 6379 resources: limits: cpu: \u0026#34;0.1\u0026#34; volumeMounts: - mountPath: /redis-master-data name: data - mountPath: /redis-master name: config volumes: - name: data emptyDir: {} - name: config configMap: name: example-redis-config items: - key: redis-config path: redis.conf 创建redis Pod\n1 kubectl apply -f redis-pod.yaml 查看创建Pod\n1 kubectl get pod/redis -o wide 输出如下：\n1 2 NAME READY STATUS RESTARTS AGE IP NODE redis 1/1 Running 0 54s 172.17.0.13 minikube 5. 访问Redis 由于mac上的minikube是先创建一个运行linux的虚拟机(node节点)，然后再在虚拟机里部署k8s的核心服务和 用户Pod，在mac里无法直接访问pod ip 但是node可以直接访问pod ip。因此我们通过下列步骤访问redis\n先登陆到node节点(虚拟机)终端 1 minikube ssh 在node节点上安装redis客户端 1 sudo apt-get install redis-cli 访问redis, 获取配置 1 2 3 4 5 6 7 8 docker@minikube:~$ redis-cli -h 172.17.0.13 -p 6379 172.17.0.13:6379\u0026gt; CONFIG GET maxmemory 1) \u0026#34;maxmemory\u0026#34; 2) \u0026#34;2097152\u0026#34; 172.17.0.13:6379\u0026gt; CONFIG GET maxmemory-policy 1) \u0026#34;maxmemory-policy\u0026#34; 2) \u0026#34;allkeys-lru\u0026#34; 172.17.0.13:6379\u0026gt; ","permalink":"https://www.aiforagc.com/posts/minikube_install/","summary":"作者最近在研究和k8s相关的项目，为了学习k8s，在mac上安装了Minikube。Minikube是一款单机搭建和管理Kubernetes","title":"快速搭建k8s学习环境：minikube实战教程"},{"content":"Go 通过三色标记法实现自动内存管理，使程序员不需要手动管理内存，从而解放了程序员的双手。然而，如果不合理使用内存，仍然会导致内存泄漏或者影响垃圾回收器的性能，从而导致 Go 程序的性能问题。\n下面是一些不合理使用内存的行为 无限制地增长切片 如果在一个循环中无限制地增长切片，将会导致程序性能严重下降。因为每次增加切片大小时，Go 都需要重新分配内存和复制数据，这些都是非常耗费性能的操作。\n在循环中不停地分配和释放内存 在循环中不断地分配和释放内存会导致 Go 的垃圾回收器频繁运行，从而影响程序性能。\n谨慎使用全局变量和单例模式 使用全局变量和单例模式也容易导致内存使用不当。全局变量和单例模式都会在程序运行时一直占用内存，可能导致内存泄漏和垃圾回收器无法及时回收内存。\n不适当地使用 map a. buckets占用大量内存 在使用 map 时，如果经过大量写入元素然后删除元素，会导致 buckets 占用大量内存。为了避免这种情况，可以采用以下方法：\n重启程序； 定期地将 map 里的元素全量拷贝到另一个 map 里。 b. 谨慎在键或者值中使用指针 bmap 这个结构体里有一个 overflow 指针，它指向溢出的 bucket。因为它是一个指针，所以 GC 的时候肯定要扫描它，也就要扫描所有的 bmap。 当map 的 key/value 都是非指针类型的话，扫描是可以避免的，直接标记整个 map 的颜色（三色标记法）就行了，不用去扫描每个 bmap 的 overflow 指针。\n底层实现方式是：\nhmap 里的 extra 结构体的 overflow 指针来 “hold” 这些 overflow 的 bucket bmap 结构体的 overflow 指针类型变成一个 unitptr 类型（这些是在编译期干的） 子字符串(子切片)造成的暂时性内存泄露 标准编译器实现让一个子字符串表达式的结果（子）字符串和基础字符串共享一个承载底层字节序列的内存块。这是一个好的设计，它不仅节省内存，而且还减少了 CPU 消耗。但是有时候它会造成暂时性的内存泄露。 比如，当下面这段代码中的demo函数被调用之后，将会造成大约1M字节的暂时性内存泄露，直到包级变量s0的值在其它某处被重新修改为止。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 var s0 string // 一个包级变量 // 一个演示目的函数。 func f(s1 string) { s0 = s1[:50] // 目前，s0和s1共享着承载它们的字节序列的同一个内存块。 // 虽然s1到这里已经不再被使用了，但是s0仍然在使用中， // 所以它们共享的内存块将不会被回收。虽然此内存块中 // 只有50字节被真正使用，而其它字节却无法再被使用。 } func demo() { s := createStringWithLengthOnHeap(1 \u0026lt;\u0026lt; 20) // 1M bytes f(s) } 防止临时性内存泄露的方法本质是s0复制字节序列内存块而不是共享。例如可以使用Go 1.10种引入的strings.Builder类型\n1 2 3 4 5 6 7 8 9 10 import \u0026#34;strings\u0026#34; var s0 string // 一个包级变量 func f(s1 string) { var b strings.Builder b.Grow(50) b.WriteString(s1[:50]) s0 = b.String() } 和子字符串情形类似，子切片也可能会造成暂时性的内存泄露。\n未重置丢失的切片元素中的指针而造成的临时性内存泄露 在下面这段代码中，f函数调用之后，s的首尾两个元素将不再可用。\n1 2 3 4 5 6 func f() []*float64 { s := []*int{new(float64), new(float64), new(float64), new(float64)} // 使用此s切片 ... return s[1:3] } f函数调用返回的切片仍在被使用中，它的各个元素就不会回收，包括首尾两个已经丢失的元素。 此时首尾两个元素引用着的两个float64值也不会被回收，即使我们不在使用这两个float64值。\n为了防止这样的暂时性内存泄露，我们必须重置丢失的元素中的指针。\n1 2 3 4 5 6 7 func f() []*float64 { s := []*float64{new(float64), new(float64), new(float64), new(float64)} // 使用此s切片 ... s[0], s[len(s)-1] = nil, nil // 重置首尾元素指针 return s[1:3] } 因此需要在删除切片元素操作中重置一些切片元素中的指针值。\n因为协程被永久阻塞而造成的永久性内存泄露 在一个程序中，有些协程可能会永久地阻塞。由于Go运行时不会杀死这些协程，它们会一直占用资源而得不到释放。\nGo运行时不会杀死处于永久阻塞状态的协程，主要有两个原因：一是有时候很难确定一个阻塞的协程是永久性的还是暂时性的；二是有时候我们可能有意让某些协程永久阻塞。\n因此，我们应该尽量避免设计中的错误，导致协程永久阻塞。\n因为没有停止不再使用的time.Ticker值而造成的永久性内存泄露 当一个time.Timer值不再被使用，一段时间后它将被自动垃圾回收掉。 但对于一个不再使用的time.Ticker值，我们必须调用它的Stop方法结束它，否则它将永远不会得到回收。\n因为不正确地使用终结器（finalizer）而造成的永久性内存泄露 将一个终结器设置到一个循环引用值组中的一个值上可能导致被此值组中的值所引用的内存块永远得不到回收。\n比如，当下面这个函数被调用后，承载着x和y的两个内存块将不保证会被逐渐回收。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func memoryLeaking() { type T struct { v [1\u0026lt;\u0026lt;20]int t *T } var finalizer = func(t *T) { fmt.Println(\u0026#34;finalizer called\u0026#34;) } var x, y T // 此SetFinalizer函数调用将使x逃逸到堆上。 runtime.SetFinalizer(\u0026amp;x, finalizer) // 下面这行将形成一个包含x和y的循环引用值组。 // 这有可能造成x和y不可回收。 x.t, y.t = \u0026amp;y, \u0026amp;x // y也逃逸到了堆上。 } GO内存使用的最佳实践 使用适当的数据类型：如果可能，使用更小的数据类型来节省内存。例如，使用 int8 代替 int，使用 uint8 代替 uint，等等。这样可以在不影响代码功能的情况下减少内存使用量。 合理使用包含指针的对象：在 Go 中，垃圾收集器只会扫描包含指针的对象。因此，如果对象不包含指针，它们就不会影响垃圾收集时间。比如，1GB byte 的 slice 事实上不会影响垃圾收集时间。一些可能性：使用 indices 代替指针，把对象分割成两部分，其中一部分不包含指针，以便减少垃圾收集时间。 避免过多的对象创建：过多的对象创建会导致额外的内存开销，应该尽量避免。在使用 new 和 make 分配内存时，应该尽量避免创建过多的对象。 预分配内存：如果知道 slice 的大小，应该在使用 make 分配内存时预分配对应的内存大小。这样可以减少内存碎片和 GC 压力。 使用内存池：使用内存池可以减少分配和释放内存的次数，从而减少内存碎片和 GC 压力。在处理大量数据时，应该尽量使用内存池。 尽早释放不需要的内存：当一个指针变量不再被使用时，应该尽早将其设置为 nil，以便让 GC 尽早回收其占用的内存。 避免大内存分配：在 Go 中，大内存分配会导致内存的碎片化，从而增加 GC 的负担。因此，应该尽量避免大内存分配。 避免过度复制：在处理大量数据时，避免过度复制可以减少内存使用量。可以使用指针或引用类型，或使用切片或映射类型，在不产生额外开销的情况下进行数据处理。 综上所述，合理使用内存需要从代码的角度出发，减少内存的分配和释放，避免产生内存碎片，以提高程序的效率和稳定性。\n","permalink":"https://www.aiforagc.com/posts/go_mem_user/","summary":"Go 通过三色标记法实现自动内存管理，使程序员不需要手动管理内存，从而解放了程序员的双手。然而，如果不合理使用内存，仍然会导致内存泄漏或者影响垃","title":"优化性能：GO内存使用的最佳实践"},{"content":" 名称： jieyong\u0026rsquo;s Blog 网址： https://www.aiforagc.com 描述： 一个记录技术、阅读、生活的博客 👉友链申请要求 秉承互换友链原则、文章定期更新、不能有太多广告、个人描述字数控制在15字内\n","permalink":"https://www.aiforagc.com/links/","summary":"名称： jieyong\u0026rsquo;s Blog 网址： https://www.aiforagc.com 描述： 一个记录技术、阅读、生活的博客 👉友链申请要求 秉承互换友链原则、文章定期更新、不能有太多广告、个人描述字数控制在15字","title":"🤝友链"},{"content":"关于我\n职业: 程序员 运动: 跑步、乒乓球、爬山 ","permalink":"https://www.aiforagc.com/about/","summary":"关于我 职业: 程序员 运动: 跑步、乒乓球、爬山","title":"🙋🏻‍♂️关于"}]